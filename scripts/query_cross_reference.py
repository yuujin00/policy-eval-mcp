import os, json, time, logging
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
from difflib import SequenceMatcher

load_dotenv()          # .env ì½ì–´ì„œ os.environ ì— ì£¼ì…

"""Privacyâ€‘policy crossâ€‘reference evaluator â€‘ 2025â€‘KR
-----------------------------------------------------
ğŸ”§ 2025â€‘06 ìˆ˜ì • (OpenAI SDK â‰¥â€¯1.18)
  â€¢ Retrieval â†’ file_search + vectorâ€‘store êµ¬ì¡° ë°˜ì˜
  â€¢ eval_title â†’ mapped_title â†’ í•­ëª© ê³ ì • í‰ê°€ êµ¬ì¡°ë¡œ ë³€ê²½
"""

#############################################################################
# ê²½ë¡œ ë° ìƒìˆ˜
#############################################################################
PDF_PATH      = "data/policies/ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ ì‘ì„±ì§€ì¹¨(2025.4.).pdf"
CRITERIA_FILE = "data/evaluation_criteria.json"
CROSS_FILE    = "results/KISA_structured_cross_reference.jsonl"
OUT_FILE      = "results/eval_result.jsonl"
CACHE_FILE    = Path("scripts/.cache/assistant.json")
MODEL         = "gpt-4o-mini"
#############################################################################

# ë¡œê¹… ----------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.FileHandler("privacy_eval.log", encoding="utf-8"),
              logging.StreamHandler()]
)

client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

#############################################################################
# 1) ìºì‹œ í™•ì¸ â€‘ Assistant / Vectorâ€‘store ì¬ì‚¬ìš©
#############################################################################
if CACHE_FILE.exists():
    cache        = json.loads(CACHE_FILE.read_text())
    assistant_id = cache["assistant_id"]
    logging.info(f"â™»ï¸  ê¸°ì¡´ Assistant ì¬ì‚¬ìš©: {assistant_id}")
else:
    CACHE_FILE.parent.mkdir(parents=True, exist_ok=True)

    logging.info("â¬†ï¸  PDF ì—…ë¡œë“œ ì¤‘ â€¦")
    uploaded = client.files.create(file=open(PDF_PATH, "rb"), purpose="assistants")
    file_id = uploaded.id

    logging.info("ğŸ—‚ï¸  Vector-store ìƒì„± â€¦")
    vs = client.vector_stores.create(name="privacy-guide-2025")
    vs_id = vs.id

    client.vector_stores.file_batches.create(
        vector_store_id=vs_id,
        file_ids=[file_id],
    )

    system_prompt = Path("scripts/system_prompt_ko.txt").read_text(encoding="utf-8")

    ast = client.beta.assistants.create(
        name="Privacy-Policy Evaluator (KR-2025)",
        model=MODEL,
        instructions=system_prompt,
        tools=[{"type": "file_search"}],
        tool_resources={
            "file_search": {
                "vector_store_ids": [vs_id]
            }
        }
    )
    assistant_id = ast.id

    CACHE_FILE.write_text(json.dumps({
        "assistant_id": assistant_id
    }))
    logging.info(f"âœ… Assistant ìƒì„±: {assistant_id}")

#############################################################################
# 2) ìœ ì‚¬í•œ í•­ëª© ë§¤í•‘
#############################################################################
def find_closest_title(title: str, criteria_list: list[str]) -> str:
    def similarity(a, b):
        return SequenceMatcher(None, a, b).ratio()
    return max(criteria_list, key=lambda x: similarity(title, x))

criteria_data = json.loads(Path(CRITERIA_FILE).read_text(encoding="utf-8"))
criteria_map = {c["title"]: c["description"] for c in criteria_data}
criteria_titles = list(criteria_map.keys())

#############################################################################
# 3) Assistant í˜¸ì¶œ í•¨ìˆ˜
#############################################################################
def ask_assistant(prompt: str, retries: int = 2) -> str:
    for attempt in range(retries + 1):
        thread = client.beta.threads.create(messages=[{"role": "user", "content": prompt}])
        run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id)

        while run.status not in {"completed", "failed", "cancelled"}:
            time.sleep(0.4)
            run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)

        if run.status != "completed":
            raise RuntimeError(f"Run {run.status}")

        msg = client.beta.threads.messages.list(thread.id).data[0]
        raw = msg.content[0].text.value.strip()
        try:
            return json.loads(raw)
        except Exception as e:
            logging.warning(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ attempt={attempt}: {e}")
            if attempt == retries:
                raise RuntimeError(f"Output parse failed: {raw.replace('\n', ' ')}")
            prompt = "í˜•ì‹ ì˜¤ë¥˜ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. JSON í•œ ì¤„ë¡œ ì¬ì¶œë ¥í•˜ì„¸ìš”.\n\n" + prompt

#############################################################################
# 4) í‰ê°€ ë£¨í”„
#############################################################################
Path("results").mkdir(exist_ok=True)

with open(CROSS_FILE, encoding="utf-8") as fin, open(OUT_FILE, "w", encoding="utf-8") as fout:
    for line in fin:
        line = line.strip()
        if not line:
            continue
        r = json.loads(line)
        eid = r["eval_id"]
        title = r["eval_title"]
        sent = r["eval_sentence"]

        mapped_title = find_closest_title(title, criteria_titles)
        description = criteria_map[mapped_title]

        prompt = f"""ë‹¤ìŒ ë¬¸ì¥ì„ ê¸°ì¤€ìœ¼ë¡œ ì•„ë˜ í•­ëª©ì˜ ê¸°ì¤€ì— ë”°ë¼ í‰ê°€í•˜ì„¸ìš”.

ã€í•­ëª©ã€‘{mapped_title}
ã€ê¸°ì¤€ ì„¤ëª…ã€‘{description}
ã€ë¬¸ì¥ã€‘{sent}

ê²°ê³¼ëŠ” ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ JSON í•œ ì¤„ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
- level: ì ì ˆ / ë¯¸í¡ / ì—†ìŒ
- íŒë‹¨_ì‚¬ìœ : í‰ê°€ ê·¼ê±°
- ê¸°ì¬: O / â–³ / X
"""

        try:
            obj = ask_assistant(prompt)
            status = "ok"
            err = ""
        except Exception as e:
            obj = {}
            status = "error"
            err = str(e)
            logging.error(f"âŒ {eid} ì‹¤íŒ¨: {e}")

        fout.write(json.dumps({
            "eval_id": eid,
            "title": mapped_title,
            "status": status,
            "result": obj,
            "error": err
        }, ensure_ascii=False) + "\n")
        logging.info(f"ğŸ“ {eid} â†’ {status}")
