# structured_split.py
# pdf íŒŒì¼ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ JSONL í˜•ì‹ìœ¼ë¡œ ë¶„í•  ì €ì¥
# 2ë²ˆ
import os
import re
import json

# âœ… ê²½ë¡œ ì„¤ì •
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
input_dir = os.path.join(ROOT_DIR, "data", "evaluation")
output_dir = os.path.join(ROOT_DIR, "data", "evaluation_structured")
os.makedirs(output_dir, exist_ok=True)

def process_file(input_path: str, output_path: str):
    with open(input_path, "r", encoding="utf-8") as f:
        text = f.read()

    lines = text.splitlines()
    chunks = []

    # âœ… 00. ì œëª©/ì„œë¡ 
    toc_start = next((i for i, line in enumerate(lines) if "ëª©ì°¨" in line), None)
    if toc_start:
        head_text = "\n".join(lines[:toc_start]).strip()
        if head_text:
            chunks.append({
                "id": "00",
                "title": "ì œëª©",
                "text": head_text
            })
    else:
        toc_start = 0

    # âœ… 01. ëª©ì°¨ ì¶”ì¶œ (ë‘ ì¤„ ì´ìƒë„ í¬í•¨)
    toc_lines = []
    i = toc_start + 1
    while i < len(lines):
        line = lines[i].strip()
        next_line = lines[i + 1].strip() if i + 1 < len(lines) else ""

        if re.match(r"^\d{1,2}\.\s", line):
            # ë‹¤ìŒ ì¤„ë„ ì œëª©ì²˜ëŸ¼ ë³´ì´ë©´ í•©ì¹¨
            if (not re.match(r"^\d{1,2}\.\s", next_line)) and next_line and len(next_line) < 60 and not re.search(r'[.ê°€-í£]{3,}', next_line):
                toc_lines.append(f"{line} {next_line}")
                i += 2
                continue
            else:
                toc_lines.append(line)
        elif re.match(r"^\d{1,2}\.\s", next_line):
            pass
        else:
            break
        i += 1

    toc_end_pos = i

    if toc_lines:
        chunks.append({
            "id": "01",
            "title": "ëª©ì°¨",
            "text": "\n".join(toc_lines)
        })

    # âœ… ë³¸ë¬¸ í•­ëª© ì¶”ì¶œ
    main_text = "\n".join(lines[toc_end_pos:])
    main_pattern = re.compile(r'(?m)^(\d{1,2})\.\s+(.+)')
    main_matches = list(main_pattern.finditer(main_text))

    for idx, match in enumerate(main_matches):
        start = match.start()
        end = main_matches[idx + 1].start() if idx + 1 < len(main_matches) else len(main_text)
        chunk_text = main_text[start:end].strip()
        title_text = match.group(2).strip().splitlines()[0]
        chunks.append({
            "id": match.group(1).zfill(2),
            "title": title_text,
            "text": chunk_text
        })

    # âœ… ì €ì¥
    with open(output_path, "w", encoding="utf-8") as f_out:
        for item in chunks:
            json.dump(item, f_out, ensure_ascii=False)
            f_out.write("\n")

    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"ğŸ“„ ì´ {len(chunks)}ê°œì˜ í•­ëª©ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

# âœ… í´ë” ë‚´ ëª¨ë“  txt ì²˜ë¦¬
if __name__ == "__main__":
    for filename in os.listdir(input_dir):
        if filename.endswith(".txt"):
            input_path = os.path.join(input_dir, filename)
            output_path = os.path.join(output_dir, filename.replace(".txt", "_structured.jsonl"))
            process_file(input_path, output_path)
            print(f"ğŸ“„ ì²˜ë¦¬ ì™„ë£Œ: {filename} â†’ {output_path}")
