# scripts/run_privacy_eval.py
# LLMì„ ì´ìš©í•œ í‰ê°€ ìˆ˜í–‰

import os
import json
import time
import logging
import datetime as dt
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
import argparse   

load_dotenv()


ts = dt.datetime.now().strftime("%y%m%d_%H%M%S")
default_out = f"results/eval_result_{ts}.jsonl"

# ---------------- CLI ì¸ì íŒŒì‹± ----------------
parser = argparse.ArgumentParser()
parser.add_argument("--pdf",
    default="data/policies/ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ ì‘ì„±ì§€ì¹¨(2025.4.).pdf")
parser.add_argument("--criteria",
    default="data/evaluation_criteria.json")
parser.add_argument("--cross",
    default="results/policy_structured_cross_reference.jsonl")
parser.add_argument("--out", default=default_out)
parser.add_argument("--model",
    default="gpt-4o-mini")
args = parser.parse_args()
# ----------------------------------------------

#############################################################################
# ê²½ë¡œ ë° ìƒìˆ˜ (ì˜¤ì§ *í•œ ë²ˆ*ë§Œ ì„ ì–¸)
#############################################################################
PDF_PATH      = args.pdf
CRITERIA_FILE = args.criteria
CROSS_FILE    = args.cross
OUT_FILE      = args.out
MODEL         = args.model
CACHE_FILE    = Path("scripts/.cache/assistant.json")
#############################################################################


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.FileHandler("scripts/privacy_eval.log", encoding="utf-8"),
              logging.StreamHandler()]
)

client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

#############################################################################
# 1) Assistant ìºì‹œ í™•ì¸ ë° ìƒì„±
#############################################################################
if CACHE_FILE.exists():
    cache = json.loads(CACHE_FILE.read_text())
    assistant_id = cache["assistant_id"]
    logging.info(f"â™»ï¸  ê¸°ì¡´ Assistant ì¬ì‚¬ìš©: {assistant_id}")
else:
    CACHE_FILE.parent.mkdir(parents=True, exist_ok=True)
    logging.info("â¬†ï¸  PDF ì—…ë¡œë“œ ì¤‘ â€¦")
    uploaded = client.files.create(file=open(PDF_PATH, "rb"), purpose="assistants")
    file_id = uploaded.id 

    logging.info("ğŸ—‚ï¸  Vector-store ìƒì„± â€¦")
    vs = client.vector_stores.create(name="privacy-guide-2025")
    vs_id = vs.id
    client.vector_stores.file_batches.create(vector_store_id=vs_id, file_ids=[file_id])

    system_prompt = Path("scripts/system_prompt_ko.txt").read_text(encoding="utf-8")
    ast = client.beta.assistants.create(
        name="Privacy-Policy Evaluator (KR-2025)",
        model=MODEL,
        instructions=system_prompt,
        tools=[{"type": "file_search"}],
        tool_resources={"file_search": {"vector_store_ids": [vs_id]}}
    )
    assistant_id = ast.id
    CACHE_FILE.write_text(json.dumps({"assistant_id": assistant_id}))
    logging.info(f"âœ… Assistant ìƒì„±: {assistant_id}")

#############################################################################
# 2) í‰ê°€ ì‹¤í–‰ í•¨ìˆ˜
#############################################################################
REF_MAP = {
    "privacy-act": "ë²•",
    "privacy-law": "ë²•",
    "privacy-decree": "ì˜",
    "privacy-notification": "ê³ ì‹œ",
}

def _map_sources(obj):
    for item in obj.get("ê·¼ê±°", []):
        item["ì¶œì²˜"] = REF_MAP.get(item.get("ì¶œì²˜", ""), item.get("ì¶œì²˜", ""))
    return obj

def ask_assistant(content, retries=2):
    for attempt in range(retries + 1):
        thread = client.beta.threads.create(messages=[{"role": "user", "content": content}])
        run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id)

        while run.status not in {"completed", "failed", "cancelled"}:
            time.sleep(0.4)
            run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)

        if run.status != "completed":
            raise RuntimeError(f"Run {run.status}")

        msg = client.beta.threads.messages.list(thread.id).data[0]
        raw = msg.content[0].text.value.strip()

        try:
            obj = json.loads(raw)
            obj = _map_sources(obj)
            required = {"í•­ëª©", "level", "ì¤€ìˆ˜", "ë²•ë ¹_ì í•©ì„±","ì§€ì¹¨_ì í•©ì„±", "íŒë‹¨_ì‚¬ìœ ", "ê·¼ê±°"}
            if not required.issubset(obj):
                raise ValueError("í‚¤ ëˆ„ë½")
            return raw
        except Exception as e:
            logging.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨ attempt={attempt}: {e}")
            if attempt == retries:
                sanitized = raw.replace("\n", " ")
                raise RuntimeError(f"assistant output parse failed: {sanitized}")
            content = "í˜•ì‹ ì˜¤ë¥˜ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ì „ ì§€ì¹¨ì„ ì¤€ìˆ˜í•˜ì—¬ JSON í•œ ì¤„ë¡œë§Œ ì¬ì¶œë ¥í•˜ì„¸ìš”.\n\n" + content

#############################################################################
# 3) í‰ê°€ ë£¨í”„ ì‹¤í–‰
#############################################################################
criteria_data = json.loads(Path(CRITERIA_FILE).read_text(encoding="utf-8"))
criteria_json = json.dumps(criteria_data, ensure_ascii=False, indent=2)
Path("results").mkdir(exist_ok=True)

with open(CROSS_FILE, encoding="utf-8") as fin, open(OUT_FILE, "w", encoding="utf-8") as fout:
    for line in fin:
        if not line.strip():
            continue
        r = json.loads(line)
        eid = r["eval_id"]
        title = r["eval_title"]
        sent = r["eval_sentence"]
        laws = r.get("similar_laws", [])

        prompt = f"""ã€í‰ê°€ ë¬¸ì¥ã€‘\n{sent}\n\nã€similar_lawsã€‘\n{json.dumps(laws, ensure_ascii=False, indent=2)}\n\nã€evaluation_criteria.jsonã€‘\n{criteria_json}\n\nìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ system_prompt ê·œê²©ëŒ€ë¡œ JSON í•œ ì¤„ë¡œë§Œ ì¶œë ¥."""

        try:
            res = ask_assistant(prompt)
            obj = json.loads(res)
            status = "ok"
            err = ""
        except Exception as e:
            obj = {}
            status = "error"
            err = str(e)
            res = ""
            logging.error(f"ã€í‰ê°€ ë¬¸ì¥ã€‘{eid} ì‹¤íŒ¨: {e}")

        fout.write(json.dumps({
            "eval_id": eid,
            "sentence": sent,
            "status": status,
            "result": obj,
            "raw": res,
            "error": err
        }, ensure_ascii=False) + "\n")
        logging.info(f"ã€í‰ê°€ ë¬¸ì¥ã€‘ {eid} â†’ {status}")

logging.info("í‰ê°€ ì™„ë£Œ: ê²°ê³¼ ì €ì¥ë¨")