import os, json, time, logging
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()          # .env ì½ì–´ì„œ os.environ ì— ì£¼ì…

#############################################################################
# ê²½ë¡œ ë° ìƒìˆ˜
#############################################################################
PDF_PATH      = "data/policies/ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ ì‘ì„±ì§€ì¹¨(2025.4.).pdf"
CRITERIA_FILE = "data/evaluation_criteria.json"
CROSS_FILE    = "results/naver_policy_structured_cross_reference.jsonl"
OUT_FILE      = "results/naver_eval_result.jsonl"
CACHE_FILE    = Path("scripts/.cache/assistant.json")  # assistant & vecâ€‘store ID ë³´ê´€
MODEL         = "gpt-4o-mini"                           # í•„ìš”ì‹œ ë³€ê²½
#############################################################################

# ë¡œê¹… ----------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.FileHandler("privacy_eval.log", encoding="utf-8"),
              logging.StreamHandler()]
)

client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

#############################################################################
# 1) ìºì‹œ í™•ì¸ â€‘ Assistant / Vectorâ€‘store ì¬ì‚¬ìš©
#############################################################################
if CACHE_FILE.exists():
    cache        = json.loads(CACHE_FILE.read_text())
    assistant_id = cache["assistant_id"]
    logging.info(f"â™»ï¸  ê¸°ì¡´ Assistant ì¬ì‚¬ìš©: {assistant_id}")
else:
    CACHE_FILE.parent.mkdir(parents=True, exist_ok=True)

    logging.info("â¬†ï¸  PDF ì—…ë¡œë“œ ì¤‘ â€¦")
    uploaded = client.files.create(file=open(PDF_PATH, "rb"), purpose="assistants")
    file_id = uploaded.id 

    logging.info("ğŸ—‚ï¸  Vector-store ìƒì„± â€¦")
    vs = client.vector_stores.create(name="privacy-guide-2025")
    vs_id = vs.id

    client.vector_stores.file_batches.create(
        vector_store_id=vs_id,
        file_ids=[file_id], 
    )

    from pathlib import Path
    system_prompt = Path("scripts/system_prompt_ko.txt").read_text(encoding="utf-8")

    ast = client.beta.assistants.create(
        name="Privacy-Policy Evaluator (KR-2025)",
        model=MODEL,
        instructions=system_prompt,
        tools=[{"type": "file_search"}],
        tool_resources={
            "file_search": {
                "vector_store_ids": [vs_id]
            }
        }
    )
    assistant_id = ast.id

    CACHE_FILE.write_text(json.dumps({
        "assistant_id": assistant_id
    }))
    logging.info(f"âœ… Assistant ìƒì„±: {assistant_id}")

#############################################################################
# 2) í—¬í¼ â€“ Assistant ì‹¤í–‰ + í›„ì²˜ë¦¬
#############################################################################

REF_MAP = {
    "privacy-act"          : "ë²•",
    "privacy-law"          : "ë²•",
    "privacy-decree"       : "ì˜",
    "privacy-notification" : "ê³ ì‹œ",
}

def _map_sources(obj: dict):
    for item in obj.get("ê·¼ê±°", []):
        src_raw = item.get("ì¶œì²˜", "")
        item["ì¶œì²˜"] = REF_MAP.get(src_raw, src_raw)
    return obj

def ask_assistant(content: str, retries: int = 2) -> str:
    for attempt in range(retries + 1):
        thread = client.beta.threads.create(messages=[{"role": "user", "content": content}])
        run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id)

        while run.status not in {"completed", "failed", "cancelled"}:
            time.sleep(0.4)
            run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)

        if run.status != "completed":
            raise RuntimeError(f"Run {run.status}")

        msg = client.beta.threads.messages.list(thread.id).data[0]
        raw = msg.content[0].text.value.strip()
        try:
            obj = json.loads(raw)
            obj = _map_sources(obj)
            required = {"í•­ëª©", "level", "ê¸°ì¬", "ë²•ë ¹_ì í•©ì„±", "ì§€ì¹¨_ì í•©ì„±", "íŒë‹¨_ì‚¬ìœ ", "ê·¼ê±°"}
            if not required.issubset(obj):
                raise ValueError("í‚¤ ëˆ„ë½")
            return raw
        except Exception as e:
            logging.warning(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨ attempt={attempt}: {e}")
            if attempt == retries:
                sanitized = raw.replace("\n", " ")
                raise RuntimeError(f"assistant output parse failed: {sanitized}")
            content = (
                "í˜•ì‹ ì˜¤ë¥˜ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ì „ ì§€ì¹¨ì„ ì¤€ìˆ˜í•˜ì—¬ JSON í•œ ì¤„ë¡œë§Œ ì¬ì¶œë ¥í•˜ì„¸ìš”."
                + "\n\n" + content)

#############################################################################
# 3) evaluation loop
#############################################################################

criteria_data = json.loads(Path(CRITERIA_FILE).read_text(encoding="utf-8"))
criteria_json = json.dumps(criteria_data, ensure_ascii=False, indent=2)
Path("results").mkdir(exist_ok=True)

with open(CROSS_FILE, encoding="utf-8") as fin, open(OUT_FILE, "w", encoding="utf-8") as fout:
    for line in fin:
        line = line.strip()
        if not line:
            continue
        r = json.loads(line)
        eid   = r["eval_id"]
        title = r["eval_title"]
        sent  = r["eval_sentence"]
        laws  = r.get("similar_laws", [])

        prompt = f"""ã€í‰ê°€ ë¬¸ì¥ã€‘\n{sent}\n\nã€similar_lawsã€‘\n{json.dumps(laws, ensure_ascii=False, indent=2)}\n\nã€evaluation_criteria.jsonã€‘\n{criteria_json}\n\nìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ system_prompt ê·œê²©ëŒ€ë¡œ JSON í•œ ì¤„ë¡œë§Œ ì¶œë ¥."""

        try:
            res = ask_assistant(prompt)
            obj = json.loads(res)
            status = "ok"
            err = ""
        except Exception as e:
            obj = {}
            status = "error"
            err = str(e)
            res = ""
            logging.error(f"âŒ {eid} ì‹¤íŒ¨: {e}")

        fout.write(json.dumps({
            "eval_id": eid,
            "sentence": sent,
            "status" : status,
            "result" : obj,
            "raw"    : res,
            "error"  : err
        }, ensure_ascii=False) + "\n")
        logging.info(f"ğŸ“ {eid} â†’ {status}")
    logging.info("ğŸ‰ í‰ê°€ ì™„ë£Œ: ê²°ê³¼ ì €ì¥ë¨")
